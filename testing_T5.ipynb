{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a4e95d1-bf05-4f44-be56-ba5eb7d6aad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lgrootde/Generative-re-tests/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "from os.path import abspath\n",
    "from pathlib import Path\n",
    "from dataclasses import field\n",
    "from typing import Optional\n",
    "from datasets import load_dataset\n",
    "import transformers\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import (\n",
    "    T5Tokenizer,\n",
    "    AutoTokenizer,\n",
    "    T5ForConditionalGeneration,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from wasabi import msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d38a629-3a77-4bbc-9719-693571022df9",
   "metadata": {},
   "source": [
    "# Load Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fa8b51d-9571-4ff2-814a-3879fe891581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the config\n",
    "import yaml\n",
    "with open('config/config_testing.yaml') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4189c844-5f2a-4b90-8b17-dd8928089e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"model_name\": \"google/t5-v1_1-base\",\n",
      "    \"dataset_vars\": {\n",
      "        \"type\": \"csv\",\n",
      "        \"dir\": \"data/cdr_seq2rel\",\n",
      "        \"split\": \"train\",\n",
      "        \"column_names\": [\n",
      "            \"input\",\n",
      "            \"relations\"\n",
      "        ]\n",
      "    },\n",
      "    \"output_dir\": \"./fine_tune_results\",\n",
      "    \"local_rank\": -1,\n",
      "    \"per_device_train_batch_size\": 1,\n",
      "    \"per_device_eval_batch_size\": 1,\n",
      "    \"gradient_accumulation_steps\": 8,\n",
      "    \"learning_rate\": 0.0002,\n",
      "    \"max_grad_norm\": 0.3,\n",
      "    \"weight_decay\": 0.001,\n",
      "    \"max_seq_length\": 512,\n",
      "    \"max_target_length\": 512,\n",
      "    \"num_train_epochs\": 0.5,\n",
      "    \"packing\": false,\n",
      "    \"padding\": true,\n",
      "    \"ignore_pad_token_for_loss\": true,\n",
      "    \"truncation\": true,\n",
      "    \"predict_with_generate\": true,\n",
      "    \"gradient_checkpointing\": true,\n",
      "    \"optim\": \"paged_adamw_32bit\",\n",
      "    \"lr_scheduler_type\": \"constant\",\n",
      "    \"max_steps\": 12,\n",
      "    \"warmup_ratio\": 0.03,\n",
      "    \"group_by_length\": true,\n",
      "    \"save_steps\": 4,\n",
      "    \"do_eval\": true,\n",
      "    \"evaluation_strategy\": \"steps\",\n",
      "    \"eval_steps\": 4,\n",
      "    \"pytorch_cuda_alloc_conf_list\": [\n",
      "        \"heuristic\",\n",
      "        \"max_split_size_mb512\"\n",
      "    ],\n",
      "    \"use_4bit\": false,\n",
      "    \"use_nested_quant\": false,\n",
      "    \"use_8bit\": false,\n",
      "    \"bnb_8bit\": {\n",
      "        \"compute_dtype\": \"float16\",\n",
      "        \"quant_type\": \"nf4\"\n",
      "    },\n",
      "    \"fp16\": false,\n",
      "    \"bf16\": false,\n",
      "    \"logging_steps\": 10\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Pretty print the config using json as a shortcut\n",
    "import json\n",
    "print(json.dumps(config, sort_keys=False, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3901495c-f095-43b8-9b97-b6b942c75f3d",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d144e56-fbc5-4d79-9df3-f51e1de3e7c4",
   "metadata": {},
   "source": [
    "First we'll load the dataset. The dataset used is the [CDR dataset in seq2rel format](https://github.com/JohnGiorgi/seq2rel-ds), This dataset is slightly altered to make it easier to use with [huggingface dataset](https://huggingface.co/docs/datasets/index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "185367d7-734b-4799-ac47-caeef0072892",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\n",
    "        config['dataset_vars']['type'], \n",
    "        data_dir=config['dataset_vars']['dir'],\n",
    "        column_names=config['dataset_vars']['column_names']\n",
    "        )\n",
    "\n",
    "dataset_train = dataset['train'].select(range(1,501)) # remove first row that contains column names\n",
    "dataset_eval = dataset['validation'].select(range(1,501)) # remove first row that contains column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f22b262-e2f7-453c-a4eb-3b7091b3f22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful function to see a random row in the dataset\n",
    "import datasets\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=5):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, datasets.ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6823529-b4f1-4473-9fa1-a0fb1306daf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>relations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Metabolic involvement in adriamycin cardiotoxicity. The cardiotoxic effects of adriamycin were studied in mammalian myocardial cells in culture as a model system. Adriamycin inhibited cell growth and the rhythmic contractions characteristic of myocardial cells in culture. A possible involvement of energy metabolism was suggested previously, and in this study the adenylate energy charge and phosphorylcreatine mole fraction were determined in the adriamycin-treated cells. The adenylate energy charge was found to be significantly decreased, while the phophorylcreatine mole fraction was unchanged. Such disparity suggests an inhibition of creatine phosphokinase. The addition of 1 mM adenosine to the myocardial cell cultures markedly increases the ATP concentration through a pathway reportedly leading to a compartmentalized ATP pool. In the adriamycin-treated cells, the addition of adenosine increased the adenylate charge and, concomitant with this inrcease, the cells' functional integrity, in terms of percentage of beating cells and rate of contractions, was maintained.</td>\n",
       "      <td>adriamycin @CHEMICAL@ cardiotoxicity ; cardiotoxic @DISEASE@ @CID@</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(dataset_train, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d843e66-6c4d-4b84-9acd-1e4e4eead779",
   "metadata": {},
   "source": [
    "The dataset has 2 columns, \"Input\" which are abstracts from various papers from pubmed and \"relations\" which are the relations between chemicals and diseases. The relations are in an novel format explained in the [seq2rel paper](https://aclanthology.org/2022.bionlp-1.2/). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4367a75a-305f-4984-89ce-04d6d64c6dbc",
   "metadata": {},
   "source": [
    "# Load tokenizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64b699fd-6ce8-4b6e-94ad-9ff916b7d982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Feb 26 23:13:00 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.43.04    Driver Version: 515.43.04    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A10          On   | 00000000:00:04.0 Off |                    0 |\n",
      "|  0%   31C    P8    19W / 150W |      4MiB / 23028MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1530      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8c3dbb8-88c0-422c-94e9-08c134087142",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "generation_config.json: 100%|██████████| 147/147 [00:00<00:00, 1.29MB/s]\n"
     ]
    }
   ],
   "source": [
    "model_name = config['model_name']\n",
    "device_map = {\"\": 0}\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = T5ForConditionalGeneration.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=device_map\n",
    ") # we specificly use T5 for COnfitional generations because it has a language modeling head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df56776-6805-4a7c-8b77-01d9d1e25b6d",
   "metadata": {},
   "source": [
    "# Test tokenizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c26ee0fa-ecf4-4071-8f1d-492b62e0a8bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A single row in the dataset is of type <class 'dict'>\n",
      "{'input': 'Naloxone reverses the antihypertensive effect of clonidine. In unanesthetized, spontaneously hypertensive rats the decrease in blood pressure and heart rate produced by intravenous clonidine, 5 to 20 micrograms/kg, was inhibited or reversed by nalozone, 0.2 to 2 mg/kg. The hypotensive effect of 100 mg/kg alpha-methyldopa was also partially reversed by naloxone. Naloxone alone did not affect either blood pressure or heart rate. In brain membranes from spontaneously hypertensive rats clonidine, 10(-8) to 10(-5) M, did not influence stereoselective binding of [3H]-naloxone (8 nM), and naloxone, 10(-8) to 10(-4) M, did not influence clonidine-suppressible binding of [3H]-dihydroergocryptine (1 nM). These findings indicate that in spontaneously hypertensive rats the effects of central alpha-adrenoceptor stimulation involve activation of opiate receptors. As naloxone and clonidine do not appear to interact with the same receptor site, the observed functional antagonism suggests the release of an endogenous opiate by clonidine or alpha-methyldopa and the possible role of the opiate in the central control of sympathetic tone.', 'relations': 'alpha-methyldopa @CHEMICAL@ hypotensive @DISEASE@ @CID@'}\n"
     ]
    }
   ],
   "source": [
    "# Show a single example of the dataset\n",
    "single_example = dataset_train[0]\n",
    "print(f\"A single row in the dataset is of type {type(single_example)}\")\n",
    "print(single_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223b2a0c-4e47-4e69-8fd3-01b9f7882812",
   "metadata": {},
   "source": [
    "Before going into the model the data has to be tokenized. Tokenization is a preprocess where the text is split up into tokens, these tokens are then conferted to their respective token ids using the vocab, token ids can then be converted into word vectors which are the raw input of the model. The attention mask shows which tokens should be given attention to in the attention layer in the model. A 1 means the token is given attention to in the attention layer a 0 means the token is ignored in that process. This is important when using padding for example, you don't want the padding tokens to be factored in during the attention process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a512cc26-2719-46ba-be6d-6ebb02f571a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name_input, column_name_output = config['dataset_vars']['column_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4008250-56c7-45eb-a0df-275499382552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1823, 24938, 782, 7211, 7, 8, 1181, 13397, 49, 324, 7, 757, 1504, 13, 3, 3903, 29, 30095, 5, 86, 73, 152, 222, 88, 17, 1601, 6, 23496, 120, 6676, 324, 7, 757, 20063, 8, 6313, 16, 1717, 1666, 11, 842, 1080, 2546, 57, 6344, 162, 10529, 3, 3903, 29, 30095, 6, 305, 12, 460, 2179, 5096, 7, 87, 8711, 6, 47, 19921, 15, 26, 42, 7211, 26, 57, 3, 29, 138, 32, 9431, 6, 3, 18189, 12, 204, 5453, 87, 8711, 5, 37, 10950, 324, 7, 757, 1504, 13, 910, 5453, 87, 8711, 491, 6977, 18, 22758, 26, 32, 102, 9, 47, 92, 14610, 7211, 26, 57, 3, 29, 9, 24938, 782, 5, 1823, 24938, 782, 2238, 410, 59, 2603, 893, 1717, 1666, 42, 842, 1080, 5, 86, 2241, 13304, 7, 45, 23496, 120, 6676, 324, 7, 757, 20063, 3, 3903, 29, 30095, 6, 335, 599, 18, 13520, 12, 335, 599, 18, 9120, 283, 6, 410, 59, 2860, 16687, 7, 15, 3437, 757, 11293, 13, 784, 519, 566, 908, 18, 29, 9, 24938, 782, 13642, 3, 29, 329, 201, 11, 3, 29, 9, 24938, 782, 6, 335, 599, 18, 13520, 12, 335, 599, 18, 7256, 283, 6, 410, 59, 2860, 3, 3903, 29, 30095, 18, 7, 413, 4715, 2317, 11293, 13, 784, 519, 566, 908, 18, 26, 23, 10656, 32, 49, 839, 13708, 630, 4077, 3, 29, 329, 137, 506, 7469, 6360, 24, 16, 23496, 120, 6676, 324, 7, 757, 20063, 8, 1951, 13, 2069, 491, 6977, 18, 9, 26, 1536, 32, 6873, 127, 22935, 7789, 5817, 257, 13, 3, 15405, 342, 15102, 7, 5, 282, 3, 29, 9, 24938, 782, 11, 3, 3903, 29, 30095, 103, 59, 2385, 12, 6815, 28, 8, 337, 15102, 353, 6, 8, 6970, 5014, 46, 2408, 32, 14378, 6490, 8, 1576, 13, 46, 414, 5255, 1162, 3, 15405, 342, 57, 3, 3903, 29, 30095, 42, 491, 6977, 18, 22758, 26, 32, 102, 9, 11, 8, 487, 1075, 13, 8, 3, 15405, 342, 16, 8, 2069, 610, 13, 29154, 5739, 5, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show what the output of the tokenizer looks like for the input task\n",
    "tokenizer_output_text = tokenizer(single_example[column_name_input])\n",
    "tokenizer_output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e310c938-1e43-4f34-82bb-a795b6e7c680",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lgrootde/Generative-re-tests/venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [491, 6977, 18, 22758, 26, 32, 102, 9, 3320, 13717, 329, 23936, 1741, 10950, 324, 7, 757, 3320, 308, 19056, 17892, 1741, 3320, 254, 4309, 1741, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show what the output of the tokenizer looks like for the output text\n",
    "with tokenizer.as_target_tokenizer():\n",
    "    tokenizer_output_rel = tokenizer(single_example[column_name_output])\n",
    "tokenizer_output_rel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99c20a8-9a3c-4482-9a58-a02df7f98086",
   "metadata": {},
   "source": [
    "Why tokenize the output? During training the model tasks is given a certain input match the expected output. To match it it needs to know where it's going wrong, so for the calculation of loss it needs the input ids of the tokenized output text. The exact training algorithm is presuambly [teacher forcing](https://machinelearningmastery.com/teacher-forcing-for-recurrent-neural-networks/). (I say presuamly here because i don't really know what training algoritm the huggingface api uses, where it's documentated, defined in the code and if it differs between models. And teacher forcing was used for training the T5 model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5ebd59-4e7c-4fa6-a089-e39c7ea39701",
   "metadata": {},
   "source": [
    "The T5 model has a max sequence input of 512. If an input exceed that it is truncated. This could cause the model to output the wrong relations because it is missing some information, certainly when a lot of important information output the conclusion of a paper is usally at the end of an abstract. So we'll check how many rows exceed the max sequence length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4d87b52-da4a-4c07-8698-950fa9bc3f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (619 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage that comes above max sequence length: 13.4\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = tokenizer(dataset_train[column_name_input])\n",
    "count = 0\n",
    "for idx, input_ids in enumerate(tokenized_dataset['input_ids']):\n",
    "    if len(input_ids) > 512:\n",
    "        # print(idx, len(input_ids))\n",
    "        count+=1\n",
    "print(f'Percentage that comes above max sequence length: {count/(idx+1)*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4be7e66-dcfd-4dac-a6fd-48611e60a1c4",
   "metadata": {},
   "source": [
    "# Create Preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf0a4504-9b5b-4f06-be6c-f6c8f8367fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_pad_token_for_loss=config['ignore_pad_token_for_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "486f3af2-710c-4b7d-b466-8c388313eeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    '''\n",
    "    This function takes a dataset of input and target sequences.\n",
    "    meant to be used with the dataset.map() function\n",
    "    '''\n",
    "\n",
    "    column_name_input, column_name_output = config['dataset_vars']['column_names']\n",
    "\n",
    "    # Split input and target\n",
    "    inputs, targets = [], []\n",
    "    for i in range(len(examples[column_name_input])):\n",
    "        if examples[column_name_input][i] and examples[column_name_output][i]: # remove pairs where one is None\n",
    "            inputs.append(examples[column_name_input][i])\n",
    "            targets.append(examples[column_name_output][i])\n",
    "\n",
    "    # Tokenize the input\n",
    "    model_inputs = tokenizer(\n",
    "        inputs, \n",
    "        max_length=config['max_seq_length'], \n",
    "        padding=config['padding'], \n",
    "        truncation=config['truncation'], \n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    # Tokenize the target sequence\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            targets, \n",
    "            max_length=config['max_seq_length'], \n",
    "            padding=config['padding'], \n",
    "            truncation=config['truncation'], \n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "    # Replace pad tokens with -100 so they don't contribute too the loss\n",
    "    if ignore_pad_token_for_loss:\n",
    "        labels[\"input_ids\"] = [\n",
    "                    [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
    "                ]\n",
    "\n",
    "    # Add tokenized target text to output\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25166871-1b9f-4225-a7ef-e9c1ed1a2261",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tokenizer on train dataset: 100%|██████████| 500/500 [00:02<00:00, 199.40 examples/s]\n",
      "Running tokenizer on train dataset: 100%|██████████| 500/500 [00:01<00:00, 252.47 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset_train.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    desc=\"Running tokenizer on train dataset\"\n",
    ")\n",
    "\n",
    "eval_dataset = dataset_eval.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    desc=\"Running tokenizer on train dataset\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d37e94f-0cc1-40eb-a6fb-6ecfa6767026",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A single row in the dataset is of type <class 'dict'>\n",
      "{'input': 'Naloxone reverses the antihypertensive effect of clonidine. In unanesthetized, spontaneously hypertensive rats the decrease in blood pressure and heart rate produced by intravenous clonidine, 5 to 20 micrograms/kg, was inhibited or reversed by nalozone, 0.2 to 2 mg/kg. The hypotensive effect of 100 mg/kg alpha-methyldopa was also partially reversed by naloxone. Naloxone alone did not affect either blood pressure or heart rate. In brain membranes from spontaneously hypertensive rats clonidine, 10(-8) to 10(-5) M, did not influence stereoselective binding of [3H]-naloxone (8 nM), and naloxone, 10(-8) to 10(-4) M, did not influence clonidine-suppressible binding of [3H]-dihydroergocryptine (1 nM). These findings indicate that in spontaneously hypertensive rats the effects of central alpha-adrenoceptor stimulation involve activation of opiate receptors. As naloxone and clonidine do not appear to interact with the same receptor site, the observed functional antagonism suggests the release of an endogenous opiate by clonidine or alpha-methyldopa and the possible role of the opiate in the central control of sympathetic tone.', 'relations': 'alpha-methyldopa @CHEMICAL@ hypotensive @DISEASE@ @CID@', 'input_ids': [1823, 24938, 782, 7211, 7, 8, 1181, 13397, 49, 324, 7, 757, 1504, 13, 3, 3903, 29, 30095, 5, 86, 73, 152, 222, 88, 17, 1601, 6, 23496, 120, 6676, 324, 7, 757, 20063, 8, 6313, 16, 1717, 1666, 11, 842, 1080, 2546, 57, 6344, 162, 10529, 3, 3903, 29, 30095, 6, 305, 12, 460, 2179, 5096, 7, 87, 8711, 6, 47, 19921, 15, 26, 42, 7211, 26, 57, 3, 29, 138, 32, 9431, 6, 3, 18189, 12, 204, 5453, 87, 8711, 5, 37, 10950, 324, 7, 757, 1504, 13, 910, 5453, 87, 8711, 491, 6977, 18, 22758, 26, 32, 102, 9, 47, 92, 14610, 7211, 26, 57, 3, 29, 9, 24938, 782, 5, 1823, 24938, 782, 2238, 410, 59, 2603, 893, 1717, 1666, 42, 842, 1080, 5, 86, 2241, 13304, 7, 45, 23496, 120, 6676, 324, 7, 757, 20063, 3, 3903, 29, 30095, 6, 335, 599, 18, 13520, 12, 335, 599, 18, 9120, 283, 6, 410, 59, 2860, 16687, 7, 15, 3437, 757, 11293, 13, 784, 519, 566, 908, 18, 29, 9, 24938, 782, 13642, 3, 29, 329, 201, 11, 3, 29, 9, 24938, 782, 6, 335, 599, 18, 13520, 12, 335, 599, 18, 7256, 283, 6, 410, 59, 2860, 3, 3903, 29, 30095, 18, 7, 413, 4715, 2317, 11293, 13, 784, 519, 566, 908, 18, 26, 23, 10656, 32, 49, 839, 13708, 630, 4077, 3, 29, 329, 137, 506, 7469, 6360, 24, 16, 23496, 120, 6676, 324, 7, 757, 20063, 8, 1951, 13, 2069, 491, 6977, 18, 9, 26, 1536, 32, 6873, 127, 22935, 7789, 5817, 257, 13, 3, 15405, 342, 15102, 7, 5, 282, 3, 29, 9, 24938, 782, 11, 3, 3903, 29, 30095, 103, 59, 2385, 12, 6815, 28, 8, 337, 15102, 353, 6, 8, 6970, 5014, 46, 2408, 32, 14378, 6490, 8, 1576, 13, 46, 414, 5255, 1162, 3, 15405, 342, 57, 3, 3903, 29, 30095, 42, 491, 6977, 18, 22758, 26, 32, 102, 9, 11, 8, 487, 1075, 13, 8, 3, 15405, 342, 16, 8, 2069, 610, 13, 29154, 5739, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [491, 6977, 18, 22758, 26, 32, 102, 9, 3320, 13717, 329, 23936, 1741, 10950, 324, 7, 757, 3320, 308, 19056, 17892, 1741, 3320, 254, 4309, 1741, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]}\n"
     ]
    }
   ],
   "source": [
    "# A look into the pre-tokenized dataset\n",
    "single_example = train_dataset[0]\n",
    "print(f\"A single row in the dataset is of type {type(single_example)}\")\n",
    "print(single_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7374863-ac54-48a7-a2aa-735d3605448b",
   "metadata": {},
   "source": [
    "# Create evaluation strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4728ed6e-e6a8-4737-95ef-0e6be0afba69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.generate(single_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5415e42d-0caf-40ca-83bb-7976c088d7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d5b78e2-9a33-4b92-8e23-5cb96cd1c036",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 6.27k/6.27k [00:00<00:00, 10.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "metric = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3060b9e-de15-4fa3-9035-0a0c94fafa8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lithium carbonate @CHEMICAL@ neurologic depression @DISEASE@ @CID@ lithium carbonate @CHEMICAL@ cyanosis @DISEASE@ @CID@ lithium carbonate @CHEMICAL@ cardiac arrhythmia @DISEASE@ @CID@']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': 1.0, 'rouge2': 1.0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_eval_example=[dataset_eval[0]['relations']]\n",
    "print(single_eval_example)\n",
    "# whats the output of metric.compute?\n",
    "metric.compute(\n",
    "    predictions=single_eval_example,\n",
    "    references=single_eval_example,\n",
    "    rouge_types=['rouge1', 'rouge2']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "336a7011-daaf-4806-8ffa-adde110c9927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 1.0, 'rouge2': 1.0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = [\"hello there\", \"general kenobi\"]\n",
    "references = [\"hello there\", \"general kenobi\"]\n",
    "metric.compute(predictions=predictions, references=references, rouge_types=['rouge1', 'rouge2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1fedda-d4e2-4422-b2cb-0e324d95478e",
   "metadata": {},
   "source": [
    "We need to define two functions:\n",
    "- a postprocess function that does the post processing of a prediction\n",
    "- A compute_metrics function that takes as input an prediction and output the mean score of that prediction?\n",
    "\n",
    "the compute metrics functions alwas takes a tuple of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32375a9b-d715-4656-9d85-c851a1d2e373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_text(preds, labels):\n",
    "        preds = [pred.strip() for pred in preds]\n",
    "        labels = [label.strip() for label in labels]\n",
    "\n",
    "        # rougeLSum expects newline after each sentence\n",
    "        # preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
    "        # labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
    "\n",
    "        return preds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d403a11-daac-436e-92b9-3c64d6f92c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "        \n",
    "    # Replace -100s used for padding as we can't decode them\n",
    "    preds = np.where(preds != -100, preds, tokenizer.pad_token_id)\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Some simple post-processing\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=False)\n",
    "    result = {k: round(v * 100, 4) for k, v in result.items()} # rounds all metric values to 4 numvers behind the comma\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens) # mean length of the generated sequences\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b54e042-d118-4dbb-898a-62a24235ff58",
   "metadata": {},
   "source": [
    "# Setting up trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29fd09e2-135c-4b8a-aa50-808615ea9866",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments = Seq2SeqTrainingArguments(\n",
    "        output_dir=config['output_dir'],\n",
    "        per_device_train_batch_size=config['per_device_train_batch_size'],\n",
    "        gradient_accumulation_steps=config['gradient_accumulation_steps'],\n",
    "        optim=config['optim'],\n",
    "        save_steps=config['save_steps'],\n",
    "        logging_steps=config['logging_steps'],\n",
    "        learning_rate=config['learning_rate'],\n",
    "        fp16=config['fp16'],\n",
    "        bf16=config['bf16'],\n",
    "        max_grad_norm=config['max_grad_norm'],\n",
    "        max_steps=config['max_steps'],\n",
    "        warmup_ratio=config['warmup_ratio'],\n",
    "        group_by_length=config['group_by_length'],\n",
    "        lr_scheduler_type=config['lr_scheduler_type'],\n",
    "        predict_with_generate=True,\n",
    "        save_total_limit=2,\n",
    "        save_strategy='steps',\n",
    "        load_best_model_at_end=True,\n",
    "        do_eval=config['do_eval'],\n",
    "        evaluation_strategy=config['evaluation_strategy'],\n",
    "        eval_steps=config['eval_steps']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4487f4f-7bb3-459a-b7f1-f741a732c328",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(\n",
    "        tokenizer,\n",
    "        model=model,\n",
    "        label_pad_token_id=-100,\n",
    "        pad_to_multiple_of=8 if config['fp16'] else None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "737025b2-4b7e-4608-94cb-3e35cd1afc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "        args=training_arguments,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6490531-fbb5-4f07-a16c-c075dd23a7ba",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "19d77396-81e3-4e57-80d0-28d004ddcb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 5/12 00:03 < 00:07, 0.91 it/s, Epoch 0.06/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>9.560709</td>\n",
       "      <td>7.409300</td>\n",
       "      <td>1.646000</td>\n",
       "      <td>7.049000</td>\n",
       "      <td>7.071500</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lgrootde/Generative-re-tests/venv/lib/python3.11/site-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You are trying to save a non contiguous tensor: `encoder.block.0.layer.0.SelfAttention.q.weight` which is not allowed. It either means you are trying to save tensors which are reference of each other in which case it's recommended to save only the full tensors, and reslice at load time, or simply call `.contiguous()` on your tensor to pack it before saving.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Generative-re-tests/venv/lib/python3.11/site-packages/transformers/trainer.py:1555\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1554\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1560\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Generative-re-tests/venv/lib/python3.11/site-packages/transformers/trainer.py:1922\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1919\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[1;32m   1920\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 1922\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1924\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m~/Generative-re-tests/venv/lib/python3.11/site-packages/transformers/trainer.py:2282\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2279\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mstep(metrics[metric_to_check])\n\u001b[1;32m   2281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 2282\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2283\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_save(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m~/Generative-re-tests/venv/lib/python3.11/site-packages/transformers/trainer.py:2350\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   2348\u001b[0m run_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_output_dir(trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[1;32m   2349\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(run_dir, checkpoint_folder)\n\u001b[0;32m-> 2350\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_internal_call\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_deepspeed_enabled:\n\u001b[1;32m   2352\u001b[0m     \u001b[38;5;66;03m# under zero3 model file itself doesn't get saved since it's bogus! Unless deepspeed\u001b[39;00m\n\u001b[1;32m   2353\u001b[0m     \u001b[38;5;66;03m# config `stage3_gather_16bit_weights_on_model_save` is True\u001b[39;00m\n\u001b[1;32m   2354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped\u001b[38;5;241m.\u001b[39msave_checkpoint(output_dir)\n",
      "File \u001b[0;32m~/Generative-re-tests/venv/lib/python3.11/site-packages/transformers/trainer.py:2843\u001b[0m, in \u001b[0;36mTrainer.save_model\u001b[0;34m(self, output_dir, _internal_call)\u001b[0m\n\u001b[1;32m   2840\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped\u001b[38;5;241m.\u001b[39msave_checkpoint(output_dir)\n\u001b[1;32m   2842\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 2843\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2845\u001b[0m \u001b[38;5;66;03m# Push to the Hub when `save_model` is called by the user.\u001b[39;00m\n\u001b[1;32m   2846\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpush_to_hub \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _internal_call:\n",
      "File \u001b[0;32m~/Generative-re-tests/venv/lib/python3.11/site-packages/transformers/trainer.py:2901\u001b[0m, in \u001b[0;36mTrainer._save\u001b[0;34m(self, output_dir, state_dict)\u001b[0m\n\u001b[1;32m   2899\u001b[0m             torch\u001b[38;5;241m.\u001b[39msave(state_dict, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, WEIGHTS_NAME))\n\u001b[1;32m   2900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2902\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_serialization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_safetensors\u001b[49m\n\u001b[1;32m   2903\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2906\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39msave_pretrained(output_dir)\n",
      "File \u001b[0;32m~/Generative-re-tests/venv/lib/python3.11/site-packages/transformers/modeling_utils.py:2187\u001b[0m, in \u001b[0;36mPreTrainedModel.save_pretrained\u001b[0;34m(self, save_directory, is_main_process, state_dict, save_function, push_to_hub, max_shard_size, safe_serialization, variant, token, save_peft_format, **kwargs)\u001b[0m\n\u001b[1;32m   2183\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m shard_file, shard \u001b[38;5;129;01min\u001b[39;00m shards\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   2184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m safe_serialization:\n\u001b[1;32m   2185\u001b[0m         \u001b[38;5;66;03m# At some point we will need to deal better with save_function (used for TPU and other distributed\u001b[39;00m\n\u001b[1;32m   2186\u001b[0m         \u001b[38;5;66;03m# joyfulness), but for now this enough.\u001b[39;00m\n\u001b[0;32m-> 2187\u001b[0m         \u001b[43msafe_save_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshard_file\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mformat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2188\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2189\u001b[0m         save_function(shard, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_directory, shard_file))\n",
      "File \u001b[0;32m~/Generative-re-tests/venv/lib/python3.11/site-packages/safetensors/torch.py:281\u001b[0m, in \u001b[0;36msave_file\u001b[0;34m(tensors, filename, metadata)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_file\u001b[39m(\n\u001b[1;32m    251\u001b[0m     tensors: Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor],\n\u001b[1;32m    252\u001b[0m     filename: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[1;32m    253\u001b[0m     metadata: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    254\u001b[0m ):\n\u001b[1;32m    255\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;124;03m    Saves a dictionary of tensors into raw bytes in safetensors format.\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 281\u001b[0m     serialize_file(\u001b[43m_flatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m, filename, metadata\u001b[38;5;241m=\u001b[39mmetadata)\n",
      "File \u001b[0;32m~/Generative-re-tests/venv/lib/python3.11/site-packages/safetensors/torch.py:475\u001b[0m, in \u001b[0;36m_flatten\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m failing:\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    468\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;124m        Some tensors share memory, this will lead to duplicate memory on disk and potential differences when loading them again: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfailing\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    473\u001b[0m     )\n\u001b[0;32m--> 475\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m{\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshape\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_tobytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\n",
      "File \u001b[0;32m~/Generative-re-tests/venv/lib/python3.11/site-packages/safetensors/torch.py:479\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m failing:\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    468\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;124m        Some tensors share memory, this will lead to duplicate memory on disk and potential differences when loading them again: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfailing\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    473\u001b[0m     )\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    476\u001b[0m     k: {\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(v\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    478\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m: v\u001b[38;5;241m.\u001b[39mshape,\n\u001b[0;32m--> 479\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43m_tobytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    480\u001b[0m     }\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m tensors\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    482\u001b[0m }\n",
      "File \u001b[0;32m~/Generative-re-tests/venv/lib/python3.11/site-packages/safetensors/torch.py:396\u001b[0m, in \u001b[0;36m_tobytes\u001b[0;34m(tensor, name)\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    390\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to save a sparse tensor: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` which this library does not support.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m You can make it a dense tensor before saving with `.to_dense()` but be aware this might\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    392\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m make a much larger file than needed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    393\u001b[0m     )\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mis_contiguous():\n\u001b[0;32m--> 396\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    397\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to save a non contiguous tensor: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` which is not allowed. It either means you\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m are trying to save tensors which are reference of each other in which case it\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms recommended to save\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m only the full tensors, and reslice at load time, or simply call `.contiguous()` on your tensor to\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    400\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m pack it before saving.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    401\u001b[0m     )\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;66;03m# Moving tensor to cpu before saving\u001b[39;00m\n\u001b[1;32m    404\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: You are trying to save a non contiguous tensor: `encoder.block.0.layer.0.SelfAttention.q.weight` which is not allowed. It either means you are trying to save tensors which are reference of each other in which case it's recommended to save only the full tensors, and reslice at load time, or simply call `.contiguous()` on your tensor to pack it before saving."
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465126b8-8241-40ab-9fcc-550148120e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generative-re-tests",
   "language": "python",
   "name": "gen_re"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
