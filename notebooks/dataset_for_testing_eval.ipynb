{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa585104-6d4b-4559-976c-010e36ae1fb5",
   "metadata": {},
   "source": [
    "# Creating dataset to test evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8892fdb-f981-4638-a67a-f900563e99bf",
   "metadata": {},
   "source": [
    "during the creation of the evaluation method it was found that the method was inable to deal with output of the model that does not adhere to the expected output structure. A dataset of model output that can slightly defiate from the the expected ouput is needed to test methodes on how to deal with output that doesn't adhere to the expected structre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8f26b6a-6978-4cce-b0bf-353cae13c89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    T5Tokenizer,\n",
    "    AutoTokenizer,\n",
    "    T5ForConditionalGeneration,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    GenerationConfig\n",
    ")\n",
    "import torch\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from wasabi import msg\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from os.path import abspath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b36a1f-736c-4f00-9a9a-de0e44b7c052",
   "metadata": {},
   "source": [
    "## Setting home directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aea61d60-6ae8-4f91-889a-8329d5d1ea68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Home directory: /home/lgrootde/Generative-re-tests\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "home_dir = Path(abspath(\"\")).parent\n",
    "\n",
    "msg.info(f\"Home directory: {home_dir}\")\n",
    "\n",
    "# Change when creating a new dataset for test purposes\n",
    "resulting_dataset_path = home_dir.joinpath(\n",
    "    \"data/testing_eval/cdr_seq2rel/test_trained_T5-3b.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc99d145-b30f-41d5-a3ef-7c4b1f6ff995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the config\n",
    "import yaml\n",
    "with open(home_dir.joinpath('config/config_T5-3b_cdr.yaml')) as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad6e6c0-42be-4d89-891a-b032356923eb",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3e417af-a7ab-466f-9655-a0f3caf42e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\n",
    "        config['dataset_vars']['type'], \n",
    "        data_dir=home_dir.joinpath(config['dataset_vars']['dir']),\n",
    "        column_names=config['dataset_vars']['column_names']\n",
    "        )\n",
    "\n",
    "dataset_eval = concatenate_datasets([dataset[split].select(range(1,501)) for split in config['splits_for_validation']]) # remove first row that contains column names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a28e7c-b256-49b0-8e4b-c13ece8d851c",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd9e751a-51c1-4765-b962-cdacb537c6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lgrootde/Generative-re-tests/venv/lib/python3.12/site-packages/transformers/models/t5/tokenization_t5_fast.py:171: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on google-t5/t5-3b automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [10:47<00:00, 215.89s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load model and tokenizer\n",
    "model_name = config['model_name']\n",
    "device_map = {\"\": 0}\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True, legacy=False)\n",
    "\n",
    "# Load model after training\n",
    "model = T5ForConditionalGeneration.from_pretrained(\n",
    "    home_dir.joinpath(\"results/checkpoint-100\"),\n",
    "    device_map=device_map,\n",
    "    local_files_only=True\n",
    ") # we specificly use T5 for Conditional generations because it has a language modeling head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861d0556-a631-4204-ad41-5bc963a8e5e2",
   "metadata": {},
   "source": [
    "### Specify generation config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "514c8eb3-bd71-4a05-8f13-d0650f5313aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generation_config = GenerationConfig(\n",
    "#     decoder_start_token_id=0,\n",
    "#     eos_token_id=1,\n",
    "#     pad_token_id=0,\n",
    "#     max_length=512,\n",
    "#     num_beam=4\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6a507b-6d7a-4e92-835f-4b4973633ac1",
   "metadata": {},
   "source": [
    "### Run model over dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a0e1a3a-60ba-488f-8d63-bbf4fd146b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [08:58<00:00,  1.08s/it]\n"
     ]
    }
   ],
   "source": [
    "test_eval_method_dataset = {\n",
    "    \"input\" : [],\n",
    "    \"expected output\" : [],\n",
    "    \"predicted\" : []\n",
    "}\n",
    "for row in tqdm(test_dataset):\n",
    "    input = row[\"input\"]\n",
    "    input_ids = tokenizer(input, return_tensors=\"pt\").input_ids.to('cuda')\n",
    "    output = model.generate(input_ids, max_length=256)\n",
    "    decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    test_eval_method_dataset[\"input\"].append(input)\n",
    "    test_eval_method_dataset[\"expected output\"].append(row[\"relations\"])\n",
    "    test_eval_method_dataset[\"predicted\"].append(decoded_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a740de-7734-4b42-bcec-e4939aa9332d",
   "metadata": {},
   "source": [
    "### Add output to dataset and save new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9db1d689-e2bd-4dbb-a030-5d620160effb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame.from_dict(test_eval_method_dataset)\n",
    "dataset.to_csv(resulting_dataset_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen_re",
   "language": "python",
   "name": "gen_re"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
