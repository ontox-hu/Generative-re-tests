{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a4e95d1-bf05-4f44-be56-ba5eb7d6aad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lgrootde/Generative-re-tests/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "from os.path import abspath\n",
    "from pathlib import Path\n",
    "from dataclasses import field\n",
    "from typing import Optional\n",
    "from datasets import load_dataset\n",
    "import transformers\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import (\n",
    "    T5Tokenizer,\n",
    "    AutoTokenizer,\n",
    "    T5ForConditionalGeneration,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    DataCollatorForSeq2Seq\n",
    ")\n",
    "from wasabi import msg\n",
    "from pathlib import Path\n",
    "from os.path import abspath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b36a1f-736c-4f00-9a9a-de0e44b7c052",
   "metadata": {},
   "source": [
    "## Setting file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aea61d60-6ae8-4f91-889a-8329d5d1ea68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Home directory: /home/lgrootde/Generative-re-tests\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "home_dir = Path(abspath(\"\")).parent\n",
    "msg.info(f\"Home directory: {home_dir}\")\n",
    "\n",
    "# Files used:\n",
    "config_path = home_dir.joinpath('config/config_testing.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d38a629-3a77-4bbc-9719-693571022df9",
   "metadata": {},
   "source": [
    "# Load Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fa8b51d-9571-4ff2-814a-3879fe891581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the config\n",
    "import yaml\n",
    "with open() as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4189c844-5f2a-4b90-8b17-dd8928089e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"model_name\": \"google/t5-v1_1-base\",\n",
      "    \"dataset_vars\": {\n",
      "        \"type\": \"csv\",\n",
      "        \"dir\": \"data/cdr_seq2rel\",\n",
      "        \"split\": \"train\",\n",
      "        \"column_names\": [\n",
      "            \"input\",\n",
      "            \"relations\"\n",
      "        ]\n",
      "    },\n",
      "    \"output_dir\": \"./fine_tune_results\",\n",
      "    \"local_rank\": -1,\n",
      "    \"per_device_train_batch_size\": 4,\n",
      "    \"per_device_eval_batch_size\": 4,\n",
      "    \"gradient_accumulation_steps\": 4,\n",
      "    \"learning_rate\": 0.0002,\n",
      "    \"max_grad_norm\": 0.3,\n",
      "    \"weight_decay\": 0.001,\n",
      "    \"max_seq_length\": 512,\n",
      "    \"max_target_length\": 512,\n",
      "    \"num_train_epochs\": 1,\n",
      "    \"padding\": true,\n",
      "    \"ignore_pad_token_for_loss\": true,\n",
      "    \"truncation\": true,\n",
      "    \"predict_with_generate\": true,\n",
      "    \"gradient_checkpointing\": true,\n",
      "    \"optim\": \"paged_adamw_32bit\",\n",
      "    \"lr_scheduler_type\": \"constant\",\n",
      "    \"max_steps\": 32,\n",
      "    \"warmup_ratio\": 0.03,\n",
      "    \"group_by_length\": true,\n",
      "    \"save_steps\": 8,\n",
      "    \"do_eval\": true,\n",
      "    \"evaluation_strategy\": \"steps\",\n",
      "    \"eval_steps\": 8,\n",
      "    \"pytorch_cuda_alloc_conf_list\": [\n",
      "        \"heuristic\",\n",
      "        \"max_split_size_mb512\"\n",
      "    ],\n",
      "    \"use_8bit\": false,\n",
      "    \"fp16\": false,\n",
      "    \"bf16\": false,\n",
      "    \"logging_steps\": 10\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Pretty print the config using json as a shortcut\n",
    "import json\n",
    "print(json.dumps(config, sort_keys=False, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3901495c-f095-43b8-9b97-b6b942c75f3d",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d144e56-fbc5-4d79-9df3-f51e1de3e7c4",
   "metadata": {},
   "source": [
    "First we'll load the dataset. The dataset used is the [CDR dataset in seq2rel format](https://github.com/JohnGiorgi/seq2rel-ds), This dataset is slightly altered to make it easier to use with [huggingface dataset](https://huggingface.co/docs/datasets/index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "185367d7-734b-4799-ac47-caeef0072892",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\n",
    "        config['dataset_vars']['type'], \n",
    "        data_dir=home_dir.joinpath(config['dataset_vars']['dir']),\n",
    "        column_names=config['dataset_vars']['column_names']\n",
    "        )\n",
    "\n",
    "dataset_train = dataset['train'].select(range(1,501)) # remove first row that contains column names\n",
    "dataset_eval = dataset['validation'].select(range(1,501)) # remove first row that contains column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f22b262-e2f7-453c-a4eb-3b7091b3f22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful function to see a random row in the dataset\n",
    "import datasets\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=5):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, datasets.ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6823529-b4f1-4473-9fa1-a0fb1306daf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>relations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Risks of the consumption of beverages containing quinine. Although the United States Food and Drug Administration banned its use for nocturnal leg cramps due to lack of safety and efficacy, quinine is widely available in beverages including tonic water and bitter lemon. Numerous anecdotal reports suggest that products containing quinine may produce neurological complications, including confusion, altered mental status, seizures, and coma, particularly in older women. Psychologists need to inquire about consumption of quinine-containing beverages as part of an evaluation process.</td>\n",
       "      <td>quinine @CHEMICAL@ confusion @DISEASE@ @CID@ quinine @CHEMICAL@ seizures @DISEASE@ @CID@ quinine @CHEMICAL@ coma @DISEASE@ @CID@</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(dataset_train, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d843e66-6c4d-4b84-9acd-1e4e4eead779",
   "metadata": {},
   "source": [
    "The dataset has 2 columns, \"Input\" which are abstracts from various papers from pubmed and \"relations\" which are the relations between chemicals and diseases. The relations are in an novel format explained in the [seq2rel paper](https://aclanthology.org/2022.bionlp-1.2/). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4367a75a-305f-4984-89ce-04d6d64c6dbc",
   "metadata": {},
   "source": [
    "# Load tokenizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64b699fd-6ce8-4b6e-94ad-9ff916b7d982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr 11 16:43:35 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100 80GB PCIe          Off | 00000001:00:00.0 Off |                    0 |\n",
      "| N/A   37C    P0              61W / 300W |      4MiB / 81920MiB |     23%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8c3dbb8-88c0-422c-94e9-08c134087142",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = config['model_name']\n",
    "device_map = {\"\": 0}\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True, legacy=False)\n",
    "model = T5ForConditionalGeneration.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=device_map\n",
    ") # we specificly use T5 for COnfitional generations because it has a language modeling head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111ad170-e421-470e-8a56-ed73a08d243a",
   "metadata": {},
   "source": [
    "# Changing the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27a4b43b-a624-45c2-9bcf-288ece09ecff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁@',\n",
       " 'CHE',\n",
       " 'M',\n",
       " 'ICAL',\n",
       " '@',\n",
       " '▁@',\n",
       " 'D',\n",
       " 'ISE',\n",
       " 'ASE',\n",
       " '@',\n",
       " '▁@',\n",
       " 'C',\n",
       " 'ID',\n",
       " '@',\n",
       " '▁',\n",
       " ';']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_characters = \"@CHEMICAL@ @DISEASE@ @CID@ ;\"\n",
    "# Tokenize the target sequence\n",
    "labels = tokenizer(\n",
    "    text_target=special_characters, \n",
    "    max_length=config['max_seq_length'], \n",
    "    padding=config['padding'], \n",
    "    truncation=config['truncation'],  \n",
    "    return_tensors='pt'\n",
    ")\n",
    "labels\n",
    "tokenizer.tokenize(special_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df56776-6805-4a7c-8b77-01d9d1e25b6d",
   "metadata": {},
   "source": [
    "# Test tokenizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c26ee0fa-ecf4-4071-8f1d-492b62e0a8bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A single row in the dataset is of type <class 'dict'>\n",
      "{'input': 'Naloxone reverses the antihypertensive effect of clonidine. In unanesthetized, spontaneously hypertensive rats the decrease in blood pressure and heart rate produced by intravenous clonidine, 5 to 20 micrograms/kg, was inhibited or reversed by nalozone, 0.2 to 2 mg/kg. The hypotensive effect of 100 mg/kg alpha-methyldopa was also partially reversed by naloxone. Naloxone alone did not affect either blood pressure or heart rate. In brain membranes from spontaneously hypertensive rats clonidine, 10(-8) to 10(-5) M, did not influence stereoselective binding of [3H]-naloxone (8 nM), and naloxone, 10(-8) to 10(-4) M, did not influence clonidine-suppressible binding of [3H]-dihydroergocryptine (1 nM). These findings indicate that in spontaneously hypertensive rats the effects of central alpha-adrenoceptor stimulation involve activation of opiate receptors. As naloxone and clonidine do not appear to interact with the same receptor site, the observed functional antagonism suggests the release of an endogenous opiate by clonidine or alpha-methyldopa and the possible role of the opiate in the central control of sympathetic tone.', 'relations': 'alpha-methyldopa @CHEMICAL@ hypotensive @DISEASE@ @CID@'}\n"
     ]
    }
   ],
   "source": [
    "# Show a single example of the dataset\n",
    "single_example = dataset_train[0]\n",
    "print(f\"A single row in the dataset is of type {type(single_example)}\")\n",
    "print(single_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223b2a0c-4e47-4e69-8fd3-01b9f7882812",
   "metadata": {},
   "source": [
    "Before going into the model the data has to be tokenized. Tokenization is a preprocess where the text is split up into tokens, these tokens are then conferted to their respective token ids using the vocab, token ids can then be converted into word vectors which are the raw input of the model. The attention mask shows which tokens should be given attention to in the attention layer in the model. A 1 means the token is given attention to in the attention layer a 0 means the token is ignored in that process. This is important when using padding for example, you don't want the padding tokens to be factored in during the attention process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a512cc26-2719-46ba-be6d-6ebb02f571a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name_input, column_name_output = config['dataset_vars']['column_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4008250-56c7-45eb-a0df-275499382552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1823, 24938, 782, 7211, 7, 8, 1181, 13397, 49, 324, 7, 757, 1504, 13, 3, 3903, 29, 30095, 5, 86, 73, 152, 222, 88, 17, 1601, 6, 23496, 120, 6676, 324, 7, 757, 20063, 8, 6313, 16, 1717, 1666, 11, 842, 1080, 2546, 57, 6344, 162, 10529, 3, 3903, 29, 30095, 6, 305, 12, 460, 2179, 5096, 7, 87, 8711, 6, 47, 19921, 15, 26, 42, 7211, 26, 57, 3, 29, 138, 32, 9431, 6, 3, 18189, 12, 204, 5453, 87, 8711, 5, 37, 10950, 324, 7, 757, 1504, 13, 910, 5453, 87, 8711, 491, 6977, 18, 22758, 26, 32, 102, 9, 47, 92, 14610, 7211, 26, 57, 3, 29, 9, 24938, 782, 5, 1823, 24938, 782, 2238, 410, 59, 2603, 893, 1717, 1666, 42, 842, 1080, 5, 86, 2241, 13304, 7, 45, 23496, 120, 6676, 324, 7, 757, 20063, 3, 3903, 29, 30095, 6, 335, 599, 18, 13520, 12, 335, 599, 18, 9120, 283, 6, 410, 59, 2860, 16687, 7, 15, 3437, 757, 11293, 13, 784, 519, 566, 908, 18, 29, 9, 24938, 782, 13642, 3, 29, 329, 201, 11, 3, 29, 9, 24938, 782, 6, 335, 599, 18, 13520, 12, 335, 599, 18, 7256, 283, 6, 410, 59, 2860, 3, 3903, 29, 30095, 18, 7, 413, 4715, 2317, 11293, 13, 784, 519, 566, 908, 18, 26, 23, 10656, 32, 49, 839, 13708, 630, 4077, 3, 29, 329, 137, 506, 7469, 6360, 24, 16, 23496, 120, 6676, 324, 7, 757, 20063, 8, 1951, 13, 2069, 491, 6977, 18, 9, 26, 1536, 32, 6873, 127, 22935, 7789, 5817, 257, 13, 3, 15405, 342, 15102, 7, 5, 282, 3, 29, 9, 24938, 782, 11, 3, 3903, 29, 30095, 103, 59, 2385, 12, 6815, 28, 8, 337, 15102, 353, 6, 8, 6970, 5014, 46, 2408, 32, 14378, 6490, 8, 1576, 13, 46, 414, 5255, 1162, 3, 15405, 342, 57, 3, 3903, 29, 30095, 42, 491, 6977, 18, 22758, 26, 32, 102, 9, 11, 8, 487, 1075, 13, 8, 3, 15405, 342, 16, 8, 2069, 610, 13, 29154, 5739, 5, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show what the output of the tokenizer looks like for the input task\n",
    "tokenizer_output_text = tokenizer(single_example[column_name_input])\n",
    "tokenizer_output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e310c938-1e43-4f34-82bb-a795b6e7c680",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lgrootde/Generative-re-tests/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3892: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [491, 6977, 18, 22758, 26, 32, 102, 9, 3320, 13717, 329, 23936, 1741, 10950, 324, 7, 757, 3320, 308, 19056, 17892, 1741, 3320, 254, 4309, 1741, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show what the output of the tokenizer looks like for the output text\n",
    "with tokenizer.as_target_tokenizer():\n",
    "    tokenizer_output_rel = tokenizer(single_example[column_name_output])\n",
    "tokenizer_output_rel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99c20a8-9a3c-4482-9a58-a02df7f98086",
   "metadata": {},
   "source": [
    "Why tokenize the output? During training the model tasks is given a certain input match the expected output. To match it it needs to know where it's going wrong, so for the calculation of loss it needs the input ids of the tokenized output text. The exact training algorithm is presuambly [teacher forcing](https://machinelearningmastery.com/teacher-forcing-for-recurrent-neural-networks/). (I say presuamly here because i don't really know what training algoritm the huggingface api uses, where it's documentated, defined in the code and if it differs between models. And teacher forcing was used for training the T5 model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5ebd59-4e7c-4fa6-a089-e39c7ea39701",
   "metadata": {},
   "source": [
    "The T5 model has a max sequence input of 512. If an input exceed that it is truncated. This could cause the model to output the wrong relations because it is missing some information, certainly when a lot of important information output the conclusion of a paper is usally at the end of an abstract. So we'll check how many rows exceed the max sequence length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4d87b52-da4a-4c07-8698-950fa9bc3f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (619 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage that comes above max sequence length: 13.4\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = tokenizer(dataset_train[column_name_input])\n",
    "count = 0\n",
    "for idx, input_ids in enumerate(tokenized_dataset['input_ids']):\n",
    "    if len(input_ids) > 512:\n",
    "        # print(idx, len(input_ids))\n",
    "        count+=1\n",
    "print(f'Percentage that comes above max sequence length: {count/(idx+1)*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4be7e66-dcfd-4dac-a6fd-48611e60a1c4",
   "metadata": {},
   "source": [
    "# Create Preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf0a4504-9b5b-4f06-be6c-f6c8f8367fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_pad_token_for_loss=config['ignore_pad_token_for_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "486f3af2-710c-4b7d-b466-8c388313eeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    '''\n",
    "    This function takes a dataset of input and target sequences.\n",
    "    meant to be used with the dataset.map() function\n",
    "    '''\n",
    "\n",
    "    column_name_input, column_name_output = config['dataset_vars']['column_names']\n",
    "\n",
    "    # Split input and target\n",
    "    inputs, targets = [], []\n",
    "    for i in range(len(examples[column_name_input])):\n",
    "        if examples[column_name_input][i] and examples[column_name_output][i]: # remove pairs where one is None\n",
    "            inputs.append(examples[column_name_input][i])\n",
    "            targets.append(examples[column_name_output][i])\n",
    "\n",
    "    # Tokenize the input\n",
    "    model_inputs = tokenizer(\n",
    "        inputs, \n",
    "        max_length=config['max_seq_length'], \n",
    "        padding=config['padding'], \n",
    "        truncation=config['truncation'], \n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    # Tokenize the target sequence\n",
    "    labels = tokenizer(\n",
    "        text_target=targets, \n",
    "        max_length=config['max_seq_length'], \n",
    "        padding=config['padding'], \n",
    "        truncation=config['truncation'],  \n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    # Replace pad tokens with -100 so they don't contribute too the loss\n",
    "    if ignore_pad_token_for_loss:\n",
    "        labels[\"input_ids\"] = [\n",
    "                    [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
    "                ]\n",
    "\n",
    "    # Add tokenized target text to output\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25166871-1b9f-4225-a7ef-e9c1ed1a2261",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tokenizer on train dataset: 100%|██████████| 500/500 [00:02<00:00, 247.83 examples/s]\n",
      "Running tokenizer on tr|ain dataset: 100%|██████████| 500/500 [00:01<00:00, 298.15 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset_train.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    desc=\"Running tokenizer on train dataset\"\n",
    ")\n",
    "\n",
    "eval_dataset = dataset_eval.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    desc=\"Running tokenizer on tr|ain dataset\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d37e94f-0cc1-40eb-a6fb-6ecfa6767026",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A single row in the dataset is of type <class 'dict'>\n",
      "{'input': 'Naloxone reverses the antihypertensive effect of clonidine. In unanesthetized, spontaneously hypertensive rats the decrease in blood pressure and heart rate produced by intravenous clonidine, 5 to 20 micrograms/kg, was inhibited or reversed by nalozone, 0.2 to 2 mg/kg. The hypotensive effect of 100 mg/kg alpha-methyldopa was also partially reversed by naloxone. Naloxone alone did not affect either blood pressure or heart rate. In brain membranes from spontaneously hypertensive rats clonidine, 10(-8) to 10(-5) M, did not influence stereoselective binding of [3H]-naloxone (8 nM), and naloxone, 10(-8) to 10(-4) M, did not influence clonidine-suppressible binding of [3H]-dihydroergocryptine (1 nM). These findings indicate that in spontaneously hypertensive rats the effects of central alpha-adrenoceptor stimulation involve activation of opiate receptors. As naloxone and clonidine do not appear to interact with the same receptor site, the observed functional antagonism suggests the release of an endogenous opiate by clonidine or alpha-methyldopa and the possible role of the opiate in the central control of sympathetic tone.', 'relations': 'alpha-methyldopa @CHEMICAL@ hypotensive @DISEASE@ @CID@', 'input_ids': [1823, 24938, 782, 7211, 7, 8, 1181, 13397, 49, 324, 7, 757, 1504, 13, 3, 3903, 29, 30095, 5, 86, 73, 152, 222, 88, 17, 1601, 6, 23496, 120, 6676, 324, 7, 757, 20063, 8, 6313, 16, 1717, 1666, 11, 842, 1080, 2546, 57, 6344, 162, 10529, 3, 3903, 29, 30095, 6, 305, 12, 460, 2179, 5096, 7, 87, 8711, 6, 47, 19921, 15, 26, 42, 7211, 26, 57, 3, 29, 138, 32, 9431, 6, 3, 18189, 12, 204, 5453, 87, 8711, 5, 37, 10950, 324, 7, 757, 1504, 13, 910, 5453, 87, 8711, 491, 6977, 18, 22758, 26, 32, 102, 9, 47, 92, 14610, 7211, 26, 57, 3, 29, 9, 24938, 782, 5, 1823, 24938, 782, 2238, 410, 59, 2603, 893, 1717, 1666, 42, 842, 1080, 5, 86, 2241, 13304, 7, 45, 23496, 120, 6676, 324, 7, 757, 20063, 3, 3903, 29, 30095, 6, 335, 599, 18, 13520, 12, 335, 599, 18, 9120, 283, 6, 410, 59, 2860, 16687, 7, 15, 3437, 757, 11293, 13, 784, 519, 566, 908, 18, 29, 9, 24938, 782, 13642, 3, 29, 329, 201, 11, 3, 29, 9, 24938, 782, 6, 335, 599, 18, 13520, 12, 335, 599, 18, 7256, 283, 6, 410, 59, 2860, 3, 3903, 29, 30095, 18, 7, 413, 4715, 2317, 11293, 13, 784, 519, 566, 908, 18, 26, 23, 10656, 32, 49, 839, 13708, 630, 4077, 3, 29, 329, 137, 506, 7469, 6360, 24, 16, 23496, 120, 6676, 324, 7, 757, 20063, 8, 1951, 13, 2069, 491, 6977, 18, 9, 26, 1536, 32, 6873, 127, 22935, 7789, 5817, 257, 13, 3, 15405, 342, 15102, 7, 5, 282, 3, 29, 9, 24938, 782, 11, 3, 3903, 29, 30095, 103, 59, 2385, 12, 6815, 28, 8, 337, 15102, 353, 6, 8, 6970, 5014, 46, 2408, 32, 14378, 6490, 8, 1576, 13, 46, 414, 5255, 1162, 3, 15405, 342, 57, 3, 3903, 29, 30095, 42, 491, 6977, 18, 22758, 26, 32, 102, 9, 11, 8, 487, 1075, 13, 8, 3, 15405, 342, 16, 8, 2069, 610, 13, 29154, 5739, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [491, 6977, 18, 22758, 26, 32, 102, 9, 3320, 13717, 329, 23936, 1741, 10950, 324, 7, 757, 3320, 308, 19056, 17892, 1741, 3320, 254, 4309, 1741, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]}\n"
     ]
    }
   ],
   "source": [
    "# A look into the pre-tokenized dataset\n",
    "single_example = train_dataset[0]\n",
    "print(f\"A single row in the dataset is of type {type(single_example)}\")\n",
    "print(single_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7374863-ac54-48a7-a2aa-735d3605448b",
   "metadata": {},
   "source": [
    "# Create evaluation strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4728ed6e-e6a8-4737-95ef-0e6be0afba69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.generate(single_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5415e42d-0caf-40ca-83bb-7976c088d7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d5b78e2-9a33-4b92-8e23-5cb96cd1c036",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3060b9e-de15-4fa3-9035-0a0c94fafa8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lithium carbonate @CHEMICAL@ neurologic depression @DISEASE@ @CID@ lithium carbonate @CHEMICAL@ cyanosis @DISEASE@ @CID@ lithium carbonate @CHEMICAL@ cardiac arrhythmia @DISEASE@ @CID@']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': 1.0, 'rouge2': 1.0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_eval_example=[dataset_eval[0]['relations']]\n",
    "print(single_eval_example)\n",
    "# whats the output of metric.compute?\n",
    "metric.compute(\n",
    "    predictions=single_eval_example,\n",
    "    references=single_eval_example,\n",
    "    rouge_types=['rouge1', 'rouge2']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "336a7011-daaf-4806-8ffa-adde110c9927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 1.0, 'rouge2': 1.0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = [\"hello there\", \"general kenobi\"]\n",
    "references = [\"hello there\", \"general kenobi\"]\n",
    "metric.compute(predictions=predictions, references=references, rouge_types=['rouge1', 'rouge2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1fedda-d4e2-4422-b2cb-0e324d95478e",
   "metadata": {},
   "source": [
    "We need to define two functions:\n",
    "- a postprocess function that does the post processing of a prediction\n",
    "- A compute_metrics function that takes as input an prediction and output the mean score of that prediction?\n",
    "\n",
    "the compute metrics functions alwas takes a tuple of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32375a9b-d715-4656-9d85-c851a1d2e373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_text(preds, labels):\n",
    "        preds = [pred.strip() for pred in preds]\n",
    "        labels = [label.strip() for label in labels]\n",
    "\n",
    "        # rougeLSum expects newline after each sentence\n",
    "        # preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
    "        # labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
    "\n",
    "        return preds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d403a11-daac-436e-92b9-3c64d6f92c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "        \n",
    "    # Replace -100s used for padding as we can't decode them\n",
    "    preds = np.where(preds != -100, preds, tokenizer.pad_token_id)\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Some simple post-processing\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=False)\n",
    "    result = {k: round(v * 100, 4) for k, v in result.items()} # rounds all metric values to 4 numvers behind the comma and make them percentages\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens) # mean length of the generated sequences\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b54e042-d118-4dbb-898a-62a24235ff58",
   "metadata": {},
   "source": [
    "# Setting up trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29fd09e2-135c-4b8a-aa50-808615ea9866",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments = Seq2SeqTrainingArguments(\n",
    "        output_dir=config['output_dir'],\n",
    "        per_device_train_batch_size=config['per_device_train_batch_size'],\n",
    "        gradient_accumulation_steps=config['gradient_accumulation_steps'],\n",
    "        optim=config['optim'],\n",
    "        save_steps=config['save_steps'],\n",
    "        logging_steps=config['logging_steps'],\n",
    "        learning_rate=config['learning_rate'],\n",
    "        fp16=config['fp16'],\n",
    "        bf16=config['bf16'],\n",
    "        max_grad_norm=config['max_grad_norm'],\n",
    "        max_steps=config['max_steps'],\n",
    "        warmup_ratio=config['warmup_ratio'],\n",
    "        group_by_length=config['group_by_length'],\n",
    "        lr_scheduler_type=config['lr_scheduler_type'],\n",
    "        predict_with_generate=True,\n",
    "        save_total_limit=2,\n",
    "        save_strategy='steps',\n",
    "        load_best_model_at_end=True,\n",
    "        do_eval=config['do_eval'],\n",
    "        evaluation_strategy=config['evaluation_strategy'],\n",
    "        eval_steps=config['eval_steps']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4487f4f-7bb3-459a-b7f1-f741a732c328",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(\n",
    "        tokenizer,\n",
    "        model=model,\n",
    "        label_pad_token_id=-100,\n",
    "        pad_to_multiple_of=8 if config['fp16'] else None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "737025b2-4b7e-4608-94cb-3e35cd1afc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "        args=training_arguments,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6490531-fbb5-4f07-a16c-c075dd23a7ba",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "19d77396-81e3-4e57-80d0-28d004ddcb67",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 3/32 00:01 < 00:53, 0.55 it/s, Epoch 0.06/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:38]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Generative-re-tests/venv/lib/python3.12/site-packages/transformers/trainer.py:1624\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1622\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1623\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1629\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Generative-re-tests/venv/lib/python3.12/site-packages/transformers/trainer.py:1961\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1958\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1960\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1961\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1964\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1965\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1966\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1967\u001b[0m ):\n\u001b[1;32m   1968\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1969\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/Generative-re-tests/venv/lib/python3.12/site-packages/transformers/trainer.py:2911\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2909\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   2910\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2911\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[0;32m~/Generative-re-tests/venv/lib/python3.12/site-packages/accelerate/accelerator.py:1966\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   1964\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1965\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1966\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Generative-re-tests/venv/lib/python3.12/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Generative-re-tests/venv/lib/python3.12/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98aaed6a-bef6-4946-a218-260b0258ef6f",
   "metadata": {},
   "source": [
    "# For compute metrics function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "465126b8-8241-40ab-9fcc-550148120e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lgrootde/Generative-re-tests/venv/lib/python3.12/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c9aaa17f-b0e2-4a1a-af5b-9c39cf43b00e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 20)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15fab3ab-a775-460a-8757-7be8cdedec6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 403)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.label_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "495b456e-26c9-41d5-be5f-0b3a33a356e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 403)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.label_ids[:10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "68c35e1f-bac2-413e-b18a-cb818c1bbe5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predictions.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f0f15498-83bb-435a-9766-9a6923bf85ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lithium carbonate @CHEMICAL@ neurologic depression @DISEASE@ @CID@ lithium carbonate @CHEMICAL@ cyanosis @DISEASE@ @CID@ lithium carbonate @CHEMICAL@ cardiac arrhythmia @DISEASE@ @CID@',\n",
       " 'phenobarbital @CHEMICAL@ dyskinesia @DISEASE@ @CID@',\n",
       " 'ammonia ; nh3 @CHEMICAL@ drowsiness @DISEASE@ @CID@ valproic acid ; vpa @CHEMICAL@ drowsiness @DISEASE@ @CID@',\n",
       " 'haloperidol @CHEMICAL@ catalepsy @DISEASE@ @CID@ apomorphine @CHEMICAL@ hyperactivity @DISEASE@ @CID@',\n",
       " 'isoproterenol ; iso @CHEMICAL@ cardiac hypertrophy @DISEASE@ @CID@ isoproterenol ; iso @CHEMICAL@ hyperplasia @DISEASE@ @CID@',\n",
       " 'butylated hydroxyanisole ; bha @CHEMICAL@ forestomach carcinogenesis ; forestomach tumorigenesis ; forestomach tumors @DISEASE@ @CID@',\n",
       " 'alfentanil @CHEMICAL@ muscle rigidity ; rigidity @DISEASE@ @CID@',\n",
       " 'edrophonium @CHEMICAL@ bradycardias @DISEASE@ @CID@',\n",
       " 'fentanyl @CHEMICAL@ muscular rigidity @DISEASE@ @CID@',\n",
       " 'epsilon-aminocaproic acid @CHEMICAL@ sagittal sinus thrombosis @DISEASE@ @CID@']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = predictions.label_ids[:10]\n",
    "labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "decoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e3ac33-c629-4a79-9ea3-77ff4f59638a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen_re",
   "language": "python",
   "name": "gen_re"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
