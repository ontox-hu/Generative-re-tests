{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa585104-6d4b-4559-976c-010e36ae1fb5",
   "metadata": {},
   "source": [
    "# Creating dataset to test evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8892fdb-f981-4638-a67a-f900563e99bf",
   "metadata": {},
   "source": [
    "during the creation of the evaluation method it was found that the method was inable to deal with output of the model that does not adhere to the expected output structure. A dataset of model output that can slightly defiate from the the expected ouput is needed to test methodes on how to deal with output that doesn't adhere to the expected structre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8f26b6a-6978-4cce-b0bf-353cae13c89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lgrootde/Generative-re-tests/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    T5Tokenizer,\n",
    "    AutoTokenizer,\n",
    "    T5ForConditionalGeneration,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    DataCollatorForSeq2Seq\n",
    ")\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from wasabi import msg\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc99d145-b30f-41d5-a3ef-7c4b1f6ff995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the config\n",
    "import yaml\n",
    "with open('config/config_T5-L_cdr.yaml') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad6e6c0-42be-4d89-891a-b032356923eb",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3e417af-a7ab-466f-9655-a0f3caf42e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\n",
    "        config['dataset_vars']['type'], \n",
    "        data_dir=config['dataset_vars']['dir'],\n",
    "        column_names=config['dataset_vars']['column_names']\n",
    "        )\n",
    "\n",
    "test_dataset = dataset['test'].select(range(1,501)) # remove first row that contains column names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a28e7c-b256-49b0-8e4b-c13ece8d851c",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd9e751a-51c1-4765-b962-cdacb537c6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lgrootde/Generative-re-tests/venv/lib/python3.12/site-packages/transformers/models/t5/tokenization_t5_fast.py:171: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on google-t5/t5-large automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load model and tokenizer\n",
    "model_name = config['model_name']\n",
    "device_map = {\"\": 0}\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True, legacy=False)\n",
    "model = T5ForConditionalGeneration.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=device_map\n",
    ") # we specificly use T5 for Conditional generations because it has a language modeling head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6a507b-6d7a-4e92-835f-4b4973633ac1",
   "metadata": {},
   "source": [
    "### Run model over dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a0e1a3a-60ba-488f-8d63-bbf4fd146b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5/500 [00:12<17:48,  2.16s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 500/500 [15:15<00:00,  1.83s/it]\n"
     ]
    }
   ],
   "source": [
    "test_eval_method_dataset = {\n",
    "    \"input\" : [],\n",
    "    \"expected output\" : [],\n",
    "    \"predicted\" : []\n",
    "}\n",
    "for row in tqdm(test_dataset):\n",
    "    input = row[\"input\"]\n",
    "    input_ids = tokenizer(input, return_tensors=\"pt\").input_ids.to('cuda')\n",
    "    output = model.generate(input_ids, max_new_tokens=config[\"max_target_length\"])\n",
    "    decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    test_eval_method_dataset[\"input\"].append(input)\n",
    "    test_eval_method_dataset[\"expected output\"].append(row[\"relations\"])\n",
    "    test_eval_method_dataset[\"predicted\"].append(decoded_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a740de-7734-4b42-bcec-e4939aa9332d",
   "metadata": {},
   "source": [
    "### Add output to dataset and save new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9db1d689-e2bd-4dbb-a030-5d620160effb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame.from_dict(test_eval_method_dataset)\n",
    "dataset.to_csv(\"data/testing_eval/cdr_seq2rel/test.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Generative_RE",
   "language": "python",
   "name": "gen_re"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
