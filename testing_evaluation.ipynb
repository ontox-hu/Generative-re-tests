{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e73e663-e567-41b5-b6da-8eabd536ebb6",
   "metadata": {},
   "source": [
    "# Extracting triples\n",
    "The model outputs relationship triples in the form of structured text. This notebook shows how the relationship triples are extracted out of that text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0704f035-6cc2-46b9-ae48-fcb1c2961c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "import yaml\n",
    "import re\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "from wasabi import msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404c1bd7-15c3-43e3-9dd1-504b2c2f7fe9",
   "metadata": {},
   "source": [
    "## Load Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c39af0e9-3211-470b-b682-d62abdd353f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the config\n",
    "with open('config/config_testing.yaml') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3901495c-f095-43b8-9b97-b6b942c75f3d",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "185367d7-734b-4799-ac47-caeef0072892",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\n",
    "        config['dataset_vars']['type'], \n",
    "        data_dir=config['dataset_vars']['dir'],\n",
    "        column_names=config['dataset_vars']['column_names']\n",
    "        )\n",
    "\n",
    "dataset_train = dataset['train'].select(range(1,501)) # remove first row that contains column names\n",
    "dataset_eval = dataset['validation'].select(range(1,501)) # remove first row that contains column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2199406d-b326-48e9-a590-cc423542e1a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "relations_in_structerd_text = dataset_train[\"relations\"]\n",
    "entity_types = {\"chemical\":\"@CHEMICAL@\", \n",
    "                \"disease\":\"@DISEASE@\"}\n",
    "rel_types = {\"chemical induced disease\":\"@CID@\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38594e59-99b5-4f91-b0c4-8cddb0075d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alpha-methyldopa @CHEMICAL@ hypotensive @DISEASE@ @CID@'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# voorbeeld\n",
    "relations_in_structerd_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3adf88b2-baa4-48c6-83e7-62f80e7044f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_on_labels(input_text, labels):\n",
    "    # Escape labels to ensure special characters are treated as literals in regex\n",
    "    escaped_labels = [re.escape(label) for label in labels]\n",
    "    # Join the labels into a regex pattern with alternation to match any of them\n",
    "    pattern = '|'.join(escaped_labels)\n",
    "    # Use re.split() with the compiled pattern, keeping the delimiters in the result\n",
    "    relation_segments = re.split(f'({pattern})', input_text)\n",
    "    # Filter out empty strings that might result from splitting\n",
    "    relation_segments = [segment for segment in relation_segments if segment]\n",
    "    return relation_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4a350195-bdfc-478a-a7d1-e12c67626e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_coreforents(ent, keep):\n",
    "    coreferents = tuple([coref.strip() for coref in ent[0].split(';')])\n",
    "    if keep and len(coreferents) > 1:\n",
    "        return (coreferents, ent[1]) \n",
    "    else:\n",
    "        return (coreferents[0], ent[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "593572c3-1c0f-4c20-9821-029428be65cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'re_label': 'CID',\n",
       "  'head_ent': {'label': 'CHEMICAL', 'text': ('lithium', 'li')},\n",
       "  'tail_ent': {'label': 'DISEASE', 'text': 'chronic renal failure'}},\n",
       " {'re_label': 'CID',\n",
       "  'head_ent': {'label': 'CHEMICAL', 'text': ('lithium', 'li')},\n",
       "  'tail_ent': {'label': 'DISEASE', 'text': 'proteinuria'}},\n",
       " {'re_label': 'CID',\n",
       "  'head_ent': {'label': 'CHEMICAL', 'text': ('lithium', 'li')},\n",
       "  'tail_ent': {'label': 'DISEASE', 'text': 'hypertension'}}]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_relation_triples(text: str, re_labels: list[str], keep_coreforents: bool = False) -> list[dict]:\n",
    "    '''\n",
    "    This function extracts the relationship triples out of structerd text. \n",
    "    This function assumes that the NER labels are in this structure: @label@\n",
    "    \n",
    "    input:\n",
    "    text: The structerd text as a string.\n",
    "    re_labels: The relationship labels.\n",
    "\n",
    "    returns:\n",
    "    A list of dictionaries\n",
    "    '''\n",
    "    # Split the input text into relation segments\n",
    "    relation_segments = split_on_labels(text, re_labels)\n",
    "    \n",
    "    # Remove the last empty segment if it exists\n",
    "    if not relation_segments[-1].strip():\n",
    "        relation_segments = relation_segments[:-1]\n",
    "\n",
    "    # Map relation label to entity text\n",
    "    entity_texts = relation_segments[::2] # All uneven elements\n",
    "    relation_labels = relation_segments[1::2] # All even elements\n",
    "    if len(entity_texts) != len(relation_labels): raise ValueError('Amount of relation labels in the text does not equal to amount of entities pairs')\n",
    "    \n",
    "    # Initialize a list to hold the relation triples\n",
    "    relations = []\n",
    "    \n",
    "    for entity_text, re_label in zip(entity_texts, relation_labels):\n",
    "        # Split head and tail entities and their labels\n",
    "        head_ent, tail_ent = [handle_coreforents(ent, keep_coreforents) for ent in re.findall(r'(.+?)\\s@(\\w+)@', entity_text)]\n",
    "        # print(f\"head_ent {head_ent} | tail_ent {tail_ent}\") #DEBUG\n",
    "        \n",
    "        re_label = re_label.split('@')[1]\n",
    "        relations.append({\n",
    "            're_label':re_label,\n",
    "            'head_ent': {'label':head_ent[1], 'text':head_ent[0]},\n",
    "            'tail_ent': {'label':tail_ent[1], 'text':tail_ent[0]}\n",
    "        })\n",
    "    \n",
    "    return relations\n",
    "\n",
    "# Example usage\n",
    "input_text = 'lithium ; li @CHEMICAL@ chronic renal failure @DISEASE@ @CID@ lithium ; li @CHEMICAL@ proteinuria @DISEASE@ @CID@ lithium ; li @CHEMICAL@ hypertension @DISEASE@ @CID@'\n",
    "relation_triples = extract_relation_triples(input_text, ['@CID@'], True)\n",
    "relation_triples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "53d6b3c0-7345-417c-8aae-689875657dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.8 ms, sys: 240 Âµs, total: 5.04 ms\n",
      "Wall time: 5.02 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "relation_triples = [extract_relation_triples(i, ['@CID@']) for i in relations_in_structerd_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6ae8b50f-6984-44a6-beb8-ec80761c3dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>structerd_text</th>\n",
       "      <th>Relation triples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alpha-methyldopa @CHEMICAL@ hypotensive @DISEA...</td>\n",
       "      <td>[{'re_label': 'CID', 'head_entity': {'label': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lidocaine @CHEMICAL@ cardiac asystole @DISEASE...</td>\n",
       "      <td>[{'re_label': 'CID', 'head_entity': {'label': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>suxamethonium ; suxamethonium chloride ; sch @...</td>\n",
       "      <td>[{'re_label': 'CID', 'head_entity': {'label': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scopolamine ; hyoscine @CHEMICAL@ overdosage @...</td>\n",
       "      <td>[{'re_label': 'CID', 'head_entity': {'label': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lithium ; li @CHEMICAL@ chronic renal failure ...</td>\n",
       "      <td>[{'re_label': 'CID', 'head_entity': {'label': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>zonisamide @CHEMICAL@ visual hallucinations @D...</td>\n",
       "      <td>[{'re_label': 'CID', 'head_entity': {'label': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>pan ; puromycin aminonucleoside @CHEMICAL@ nep...</td>\n",
       "      <td>[{'re_label': 'CID', 'head_entity': {'label': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>ticlopidine @CHEMICAL@ aplastic anemia @DISEAS...</td>\n",
       "      <td>[{'re_label': 'CID', 'head_entity': {'label': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>scopolamine @CHEMICAL@ amnesia @DISEASE@ @CID@...</td>\n",
       "      <td>[{'re_label': 'CID', 'head_entity': {'label': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>apomorphine @CHEMICAL@ hypothermia @DISEASE@ @...</td>\n",
       "      <td>[{'re_label': 'CID', 'head_entity': {'label': ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        structerd_text  \\\n",
       "0    alpha-methyldopa @CHEMICAL@ hypotensive @DISEA...   \n",
       "1    lidocaine @CHEMICAL@ cardiac asystole @DISEASE...   \n",
       "2    suxamethonium ; suxamethonium chloride ; sch @...   \n",
       "3    scopolamine ; hyoscine @CHEMICAL@ overdosage @...   \n",
       "4    lithium ; li @CHEMICAL@ chronic renal failure ...   \n",
       "..                                                 ...   \n",
       "495  zonisamide @CHEMICAL@ visual hallucinations @D...   \n",
       "496  pan ; puromycin aminonucleoside @CHEMICAL@ nep...   \n",
       "497  ticlopidine @CHEMICAL@ aplastic anemia @DISEAS...   \n",
       "498  scopolamine @CHEMICAL@ amnesia @DISEASE@ @CID@...   \n",
       "499  apomorphine @CHEMICAL@ hypothermia @DISEASE@ @...   \n",
       "\n",
       "                                      Relation triples  \n",
       "0    [{'re_label': 'CID', 'head_entity': {'label': ...  \n",
       "1    [{'re_label': 'CID', 'head_entity': {'label': ...  \n",
       "2    [{'re_label': 'CID', 'head_entity': {'label': ...  \n",
       "3    [{'re_label': 'CID', 'head_entity': {'label': ...  \n",
       "4    [{'re_label': 'CID', 'head_entity': {'label': ...  \n",
       "..                                                 ...  \n",
       "495  [{'re_label': 'CID', 'head_entity': {'label': ...  \n",
       "496  [{'re_label': 'CID', 'head_entity': {'label': ...  \n",
       "497  [{'re_label': 'CID', 'head_entity': {'label': ...  \n",
       "498  [{'re_label': 'CID', 'head_entity': {'label': ...  \n",
       "499  [{'re_label': 'CID', 'head_entity': {'label': ...  \n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'structerd_text': relations_in_structerd_text, 'Relation triples': relation_triples})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0775f7-9a04-4e53-b531-6b1c5fd94fe6",
   "metadata": {},
   "source": [
    "# Using ð¤ Evaluate to calculate accuracy, f1, precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7851e40c-1195-4a26-ad50-02b87605877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_metrics = evaluate.combine([\"f1\", \"precision\", \"recall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b11f82b4-d27d-497d-a6cb-bb8064f8edbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.5, 'precision': 0.5, 'recall': 0.5}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_metrics.compute(\n",
    "    predictions=[0,1,1],\n",
    "    references=[1,0,1]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faed103-32b2-4c7b-a9cb-05f7999e42ab",
   "metadata": {},
   "source": [
    "All of these metrics take input as a list of ints.\n",
    "\n",
    "documentation:\n",
    "- [accuracy](https://huggingface.co/spaces/evaluate-metric/accuracy)\n",
    "- [precision](https://huggingface.co/spaces/evaluate-metric/precision)\n",
    "- [recall](https://huggingface.co/spaces/evaluate-metric/recall)\n",
    "- [f1](https://huggingface.co/spaces/evaluate-metric/f1)\n",
    "\n",
    "so the extract relation triples needs to work on the input ids. Or the text needs to be converted to ints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e58bc04-4fee-43a0-aa56-409bc6d0ba3e",
   "metadata": {},
   "source": [
    "## Converting text to ints method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c794d840-8053-4fcf-86c4-9bf42aa65857",
   "metadata": {},
   "source": [
    "Because we're doing a relation extraction from a document, evaluating the output will be a bit different from usual methods. This method will be based on if the set of entities or relation in the predictions are also found in the set of entities and relations in the reference. The sequence of entities and relations are irrelivant. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63803aa-f42c-4831-8e39-fec24462aca9",
   "metadata": {},
   "source": [
    "### Named entity recoginition scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e467babe-0888-4762-9c4d-6dfb940ac381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'CID': {'CHEMICAL': ['lithium', 'li'], 'DISEASE': 'chronic renal failure'}},\n",
       " {'CID': {'CHEMICAL': ['lithium', 'li'], 'DISEASE': 'proteinuria'}},\n",
       " {'CID': {'CHEMICAL': ['lithium', 'li'], 'DISEASE': 'hypertension'}}]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# starting point\n",
    "index = 4\n",
    "relation_triples[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "43b66e6d-777e-474e-95ae-7ef6727b461f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = relation_triples[index]\n",
    "references = relation_triples[index]\n",
    "\n",
    "### Define group of entities in the reference\n",
    "entities_text = list()\n",
    "for relation in references:\n",
    "    nested_list = list(relation.values())[0] # Elements can be list if there is a coreferent mention\n",
    "    # This next list comprehension is barely readable but if an element is a sublist it is flattend \n",
    "    # if an element is a string it's kept as it is. \n",
    "    entities_text.extend([item for sublist in nested_list.values() for item in (sublist if isinstance(sublist, list) else [sublist])])\n",
    "\n",
    "### Check if a prediction is in the group of reference entities\n",
    "for pred in predictions:\n",
    "    for pred_ent in list(pred.values())[0].values():\n",
    "        if isinstance(pred_ent, list):\n",
    "        else:\n",
    "            if pred_ent in entities_text:\n",
    "                \n",
    "    # Remove entity texts from the group if there is a match\n",
    "# Check if the labels match\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09029e6a-5cf6-4f29-b489-6a0b09a2bc3a",
   "metadata": {},
   "source": [
    "### Relation extraxtion scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068286bd-3b17-4aad-b91a-3965b3cb7acc",
   "metadata": {},
   "source": [
    "## Using inputs ids method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "153d55a5-e7d7-440d-a694-88bab6c310d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer to access input ids\n",
    "model_name = config['model_name']\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True, legacy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef345b58-0f57-470a-9648-e9c79fa76d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mâ¹ Output in text:\u001b[0m\n",
      "alpha-methyldopa @CHEMICAL@ hypotensive @DISEASE@ @CID@\n",
      "\n",
      "\u001b[38;5;4mâ¹ Output as input ids:\u001b[0m\n",
      "tensor([[  491,  6977,    18, 22758,    26,    32,   102,     9,  3320, 13717,\n",
      "           329, 23936,  1741, 10950,   324,     7,   757,  3320,   308, 19056,\n",
      "         17892,  1741,  3320,   254,  4309,  1741,     1]])\n",
      "\n",
      "\u001b[38;5;4mâ¹ Input ids of entity labels\u001b[0m\n",
      "chemical : @CHEMICAL@\n",
      "tokens:['â@', 'CHE', 'M', 'ICAL', '@']\n",
      "input ids: tensor([ 3320, 13717,   329, 23936,  1741])\n",
      "\n",
      "disease : @DISEASE@\n",
      "tokens:['â@', 'D', 'ISE', 'ASE', '@']\n",
      "input ids: tensor([ 3320,   308, 19056, 17892,  1741])\n",
      "\n",
      "\u001b[38;5;4mâ¹ Input ids of relation labels\u001b[0m\n",
      "chemical induced disease : @CID@\n",
      "tokens:['â@', 'C', 'ID', '@']\n",
      "input ids: tensor([3320,  254, 4309, 1741])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# voorbeeld\n",
    "msg.info(f\"Output in text:\")\n",
    "print(relations_in_structerd_text[0]+'\\n')\n",
    "input_ids=tokenizer(relations_in_structerd_text[0], return_tensors=\"pt\").input_ids\n",
    "msg.info(f\"Output as input ids:\")\n",
    "print(input_ids)\n",
    "print() \n",
    "\n",
    "msg.info(\"Input ids of entity labels\")\n",
    "for key, value in entity_types.items():\n",
    "    input_ids = tokenizer(value, return_tensors=\"pt\").input_ids\n",
    "    tokens = tokenizer.tokenize(value)\n",
    "    print(f\"{key} : {value}\\ntokens:{tokens}\\ninput ids: {input_ids[0][:-1]}\"+\"\\n\")\n",
    "\n",
    "msg.info(\"Input ids of relation labels\")\n",
    "for key, value in rel_types.items():\n",
    "    input_ids = tokenizer(value, return_tensors=\"pt\").input_ids\n",
    "    tokens = tokenizer.tokenize(value)\n",
    "    print(f\"{key} : {value}\\ntokens:{tokens}\\ninput ids: {input_ids[0][:-1]}\"+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab07d77-18e2-4edf-9a85-9e443c299088",
   "metadata": {},
   "source": [
    "We can use the unique sequence of input ids of the entity and relation labels to extract the input ids of the entity text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2c3084-e19d-499f-952a-77a2cddd5ddd",
   "metadata": {},
   "source": [
    "### Custom implementation of precision, recall and f1 for RE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "3a345bbf-7f6e-4e60-bd20-46a57d9669b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_metric(predictions: list[str], references: list[str]):\n",
    "    \n",
    "    tp = 0 # True positive count\n",
    "    fp = 0 # False positive count\n",
    "    fn = 0 # False negative count\n",
    "    \n",
    "    # Define groups\n",
    "    for pred_text, ref_text in zip(predictions, references):\n",
    "    \n",
    "        predictions = extract_relation_triples(pred_text, ['@CID@'], True)\n",
    "        references = extract_relation_triples(ref_text, ['@CID@'], True)\n",
    "    \n",
    "        for pred in predictions:\n",
    "            if pred in references: # True positive\n",
    "                tp=+1\n",
    "                references.remove(pred)\n",
    "            else: # False positive\n",
    "                fp+=1\n",
    "                \n",
    "        # False negative\n",
    "        fn+=len(references)\n",
    "\n",
    "    # Calculate metrics\n",
    "    if (tp+fp) == 0: precision=0.0\n",
    "    else: precision = tp/(tp+fp)\n",
    "\n",
    "    if (tp+fn) == 0: recall=0.0\n",
    "    else: recall = tp/(tp+fn)\n",
    "\n",
    "    if (precision+recall) == 0: f1=0.0\n",
    "    else: f1 = 2 * ((precision*recall)/(precision+recall))\n",
    "\n",
    "    return {'re_precision':precision, 're_recall':recall, 're_f1':f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "34e851c2-9872-42a2-809d-eedd05e7a5f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'re_precision': 1.0, 're_recall': 1.0, 're_f1': 1.0}"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch = relations_in_structerd_text[:10]\n",
    "predictions = example_batch\n",
    "references = example_batch\n",
    "re_metric(predictions, references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92509957-162e-4625-bc3d-7d7ffed84ee9",
   "metadata": {},
   "source": [
    "### Custom implementation of precision, recall and f1 for NER:\n",
    "This function should take a list of predicted outputs and a list of references. The lists are a list of strings, the strings being the decoded output of the model (using `tokenizer.batch_decode()`)\n",
    "\n",
    "The output should be a dictionary with `key : value` pairs of `name metric : value of metric`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "71ceb1be-ca78-487b-9541-fc2895710c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group(relation_triples):\n",
    "    group = []\n",
    "    for rel in relation_triples:\n",
    "        group.append(rel['head_ent'])\n",
    "        group.append(rel['tail_ent'])\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b7b997c5-2fe7-44bf-bdd0-07bc5f9b73f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'re_label': 'CID',\n",
       "  'head_ent': {'label': 'CHEMICAL', 'text': ('lithium', 'li')},\n",
       "  'tail_ent': {'label': 'DISEASE', 'text': 'chronic renal failure'}},\n",
       " {'re_label': 'CID',\n",
       "  'head_ent': {'label': 'CHEMICAL', 'text': ('lithium', 'li')},\n",
       "  'tail_ent': {'label': 'DISEASE', 'text': 'proteinuria'}},\n",
       " {'re_label': 'CID',\n",
       "  'head_ent': {'label': 'CHEMICAL', 'text': ('lithium', 'li')},\n",
       "  'tail_ent': {'label': 'DISEASE', 'text': 'hypertension'}}]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relation_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9262a137-951f-45c5-94c7-9dd2c8b62839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'CHEMICAL', 'text': ('lithium', 'li')},\n",
       " {'label': 'DISEASE', 'text': 'chronic renal failure'},\n",
       " {'label': 'CHEMICAL', 'text': ('lithium', 'li')},\n",
       " {'label': 'DISEASE', 'text': 'proteinuria'},\n",
       " {'label': 'CHEMICAL', 'text': ('lithium', 'li')},\n",
       " {'label': 'DISEASE', 'text': 'hypertension'}]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing get_group\n",
    "get_group(relation_triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "d30c9c5e-db77-4eff-ae29-cbbebbbdeb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A single ent: {'label': 'CHEMICAL', 'text': ('lithium', 'li')}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'label': 'CHEMICAL', 'text': 'lithium'}, {'label': 'CHEMICAL', 'text': 'li'})"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing split_coferents\n",
    "print(f\"A single ent: {relation_triples[0]['head_ent']}\")\n",
    "split_coferents(relation_triples[0]['head_ent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "df69a646-ff02-4371-b4dd-41758550ad1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_coferents(ent):\n",
    "    if isinstance(ent['text'], tuple):\n",
    "        return tuple([{\"label\":ent[\"label\"], \"text\":ent['text'][i]} for i in range(len(ent['text']))])\n",
    "    else:\n",
    "        return ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "f9cf6072-5e7d-4749-9c55-f740a48cc3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_coferents(group):\n",
    "    result = {}\n",
    "    group = [split_coferents(ent) for ent in group] # Split coferents into two entities\n",
    "    for ent in group:\n",
    "        if isinstance(ent, tuple):\n",
    "            for i in range(len(ent)):\n",
    "                result[frozenset(ent[i].items())] = ent\n",
    "        else:\n",
    "            result[frozenset(ent.items())] = (ent,)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "6ad5ddc1-cded-4c4e-9a65-adf77900210d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'re_label': 'CID',\n",
       "  'head_ent': {'label': 'CHEMICAL', 'text': ('lithium', 'li')},\n",
       "  'tail_ent': {'label': 'DISEASE', 'text': 'chronic renal failure'}},\n",
       " {'re_label': 'CID',\n",
       "  'head_ent': {'label': 'CHEMICAL', 'text': ('lithium', 'li')},\n",
       "  'tail_ent': {'label': 'DISEASE', 'text': 'proteinuria'}},\n",
       " {'re_label': 'CID',\n",
       "  'head_ent': {'label': 'CHEMICAL', 'text': ('lithium', 'li')},\n",
       "  'tail_ent': {'label': 'DISEASE', 'text': 'hypertension'}}]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relation_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "40151f41-5553-46e0-a3c7-cd0d18141c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{frozenset({('label', 'CHEMICAL'),\n",
       "            ('text', 'lithium')}): ({'label': 'CHEMICAL',\n",
       "   'text': 'lithium'}, {'label': 'CHEMICAL', 'text': 'li'}),\n",
       " frozenset({('label', 'CHEMICAL'),\n",
       "            ('text', 'li')}): ({'label': 'CHEMICAL',\n",
       "   'text': 'lithium'}, {'label': 'CHEMICAL', 'text': 'li'}),\n",
       " frozenset({('label', 'DISEASE'),\n",
       "            ('text', 'chronic renal failure')}): ({'label': 'DISEASE',\n",
       "   'text': 'chronic renal failure'},),\n",
       " frozenset({('label', 'DISEASE'),\n",
       "            ('text', 'proteinuria')}): ({'label': 'DISEASE',\n",
       "   'text': 'proteinuria'},),\n",
       " frozenset({('label', 'DISEASE'),\n",
       "            ('text', 'hypertension')}): ({'label': 'DISEASE',\n",
       "   'text': 'hypertension'},)}"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing map_coferents\n",
    "group = get_group(relation_triples)\n",
    "map_coferents(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "e3768189-5bef-4358-b017-1f34f748dd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n"
     ]
    }
   ],
   "source": [
    "example_batch = relations_in_structerd_text[:10]\n",
    "predictions = example_batch\n",
    "references = example_batch\n",
    "\n",
    "coferent_matching = \"relaxed\"\n",
    "predictions = example_batch\n",
    "references = example_batch\n",
    "\n",
    "tp = 0 # True positive count\n",
    "fp = 0 # False positive count\n",
    "fn = 0 # False negative count\n",
    "for pred_text, ref_text in zip(predictions, references):\n",
    "    # Define groups\n",
    "    pred_group = get_group(extract_relation_triples(pred_text, ['@CID@'], True))\n",
    "    ref_group = get_group(extract_relation_triples(ref_text, ['@CID@'], True))\n",
    "\n",
    "    if coferent_matching == \"relaxed\":\n",
    "        # Create mapping from a coferent mentions to all coferent mentions\n",
    "        mapping_coferent = map_coferents(ref_group)\n",
    "\n",
    "        pred_group = [split_coferents(ent) for ent in pred_group] # Split coferents into multiple entities \n",
    "        # print(f\"pred_group before flattening: {pred_group}\") # DEBUG\n",
    "        pred_group = [item for sublist in pred_group for item in (sublist if isinstance(sublist, tuple) else [sublist])] # Flatten list\n",
    "        # print(f\"pred_group after flattening: {pred_group}\"+'\\n') # DEBUG\n",
    "\n",
    "        ref_group = [split_coferents(ent) for ent in ref_group] # Split coferents into multiple entities \n",
    "        ref_group = [item for sublist in ref_group for item in (sublist if isinstance(sublist, tuple) else [sublist])] # Flatten list\n",
    "\n",
    "    # print(f\"pred_group: {pred_group}\\nref_group: {ref_group}\") #DEBUG\n",
    "    # print(f\"mapping: {mapping_coferent}\")\n",
    "    checked_coferent_pred = []\n",
    "    for ent in pred_group:\n",
    "        # print(ent) # DEBUG\n",
    "        # print(ref_group) # DEBUG\n",
    "        # print() #DEBUG\n",
    "        if ent in ref_group: # True positive\n",
    "            tp += 1\n",
    "            # Remove all instances of the coferent mentions\n",
    "            if coferent_matching == \"relaxed\": \n",
    "                [ref_group.remove(i) for i in mapping_coferent[frozenset(ent.items())]]\n",
    "                checked_coferent_pred.extend([i for i in mapping_coferent[frozenset(ent.items())]])\n",
    "            else: ref_group.remove(ent) \n",
    "            continue\n",
    "        elif ent not in ref_group and ent not in checked_coferent_pred: # False positive\n",
    "            fp += 1\n",
    "    fn += len(ref_group) # False negative \n",
    "    # print(f\"TP: {tp}, FP: {fp}, FN: {fn}\") #DEBUG\n",
    "\n",
    "# Calculate metrics\n",
    "if (tp+fp) == 0: precision=0.0\n",
    "else: precision = tp/(tp+fp)\n",
    "\n",
    "if (tp+fn) == 0: recall=0.0\n",
    "else: recall = tp/(tp+fn)\n",
    "\n",
    "if (precision+recall) == 0: f1=0.0\n",
    "else: f1 = 2 * ((precision*recall)/(precision+recall))\n",
    "\n",
    "print({'precision':precision, 'recall':recall, 'f1':f1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dc0064-e2c5-43f5-b8f6-929d255cbac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_metric(predictions: list[str], references: list[str], coferent_matching: str =\"relaxed\", re_labels: list[str]) -> dict:\n",
    "    '''\n",
    "    Calculates the precision, recall and f1-score for document named entity recognition. \n",
    "    input:\n",
    "        predictions: \n",
    "            List of decoded outputs of the model\n",
    "        references: \n",
    "            List of decoded gold data\n",
    "        coferent_matching: \n",
    "            Wheter to use the coferent mentions to match named entities. can be either \"relaxed\" or \"strict\".\n",
    "            relaxed meaning that all coferent mentions might be used to match a predicted named entity to a reference entity\n",
    "            strict meaning the model needs to have all coferent mentions correct to count as a match. (including the sequence)\n",
    "        re_labels\n",
    "            Which relation extraxtion labels are used.\n",
    "    output\n",
    "        a dictionary with the key value pairs of metric_name : metric value\n",
    "    '''\n",
    "    tp = 0 # True positive count\n",
    "    fp = 0 # False positive count\n",
    "    fn = 0 # False negative count\n",
    "    for pred_text, ref_text in zip(predictions, references):\n",
    "        # Define groups\n",
    "        pred_group = get_group(extract_relation_triples(pred_text, ['@CID@'], True))\n",
    "        ref_group = get_group(extract_relation_triples(ref_text, ['@CID@'], True))\n",
    "    \n",
    "        if coferent_matching == \"relaxed\":\n",
    "            # Create mapping from a coferent mentions to all coferent mentions\n",
    "            mapping_coferent = map_coferents(ref_group)\n",
    "    \n",
    "            pred_group = [split_coferents(ent) for ent in pred_group] # Split coferents into multiple entities \n",
    "            # print(f\"pred_group before flattening: {pred_group}\") # DEBUG\n",
    "            pred_group = [item for sublist in pred_group for item in (sublist if isinstance(sublist, tuple) else [sublist])] # Flatten list\n",
    "            # print(f\"pred_group after flattening: {pred_group}\"+'\\n') # DEBUG\n",
    "    \n",
    "            ref_group = [split_coferents(ent) for ent in ref_group] # Split coferents into multiple entities \n",
    "            ref_group = [item for sublist in ref_group for item in (sublist if isinstance(sublist, tuple) else [sublist])] # Flatten list\n",
    "    \n",
    "        # print(f\"pred_group: {pred_group}\\nref_group: {ref_group}\") #DEBUG\n",
    "        # print(f\"mapping: {mapping_coferent}\")\n",
    "        checked_coferent_pred = []\n",
    "        for ent in pred_group:\n",
    "            # print(ent) # DEBUG\n",
    "            # print(ref_group) # DEBUG\n",
    "            # print() #DEBUG\n",
    "            if ent in ref_group: # True positive\n",
    "                tp += 1\n",
    "                # Remove all instances of the coferent mentions\n",
    "                if coferent_matching == \"relaxed\": \n",
    "                    [ref_group.remove(i) for i in mapping_coferent[frozenset(ent.items())]]\n",
    "                    checked_coferent_pred.extend([i for i in mapping_coferent[frozenset(ent.items())]])\n",
    "                else: ref_group.remove(ent) \n",
    "                continue\n",
    "            elif ent not in ref_group and ent not in checked_coferent_pred: # False positive\n",
    "                fp += 1\n",
    "        fn += len(ref_group) # False negative \n",
    "        # print(f\"TP: {tp}, FP: {fp}, FN: {fn}\") #DEBUG\n",
    "    \n",
    "    # Calculate metrics\n",
    "    if (tp+fp) == 0: precision=0.0\n",
    "    else: precision = tp/(tp+fp)\n",
    "    \n",
    "    if (tp+fn) == 0: recall=0.0\n",
    "    else: recall = tp/(tp+fn)\n",
    "    \n",
    "    if (precision+recall) == 0: f1=0.0\n",
    "    else: f1 = 2 * ((precision*recall)/(precision+recall))\n",
    "    \n",
    "    return {'ner_precision':precision, 'ner_recall':recall, 'ner_f1':f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd9ef04-c7cb-41e0-acb4-d1150242fdd3",
   "metadata": {},
   "source": [
    "## Loading the model to evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467b39b5-bc42-422c-a85a-a2f8b46ab49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=device_map"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Generative_RE",
   "language": "python",
   "name": "gen_re"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
